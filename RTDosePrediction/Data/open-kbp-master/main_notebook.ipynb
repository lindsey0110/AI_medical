{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BGZduk0-bBP"
   },
   "source": [
    "<center>    \n",
    "<h3>American Association of Physicists in Medicine</h3>    \n",
    "<h3>Grand Challenge 2020</h3> \n",
    "<h3>OpenKBP</h3>\n",
    "<hr>\n",
    "<h1>Introduction for Google Colab</h1>\n",
    "<h3>January 25, 2022</h3>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before running this notebook, make a directory in the main directory of your Google Drive and name it open-kbp. The \n",
    "code-block below will mount your Google Drive and give you access to all your files from this notebook. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount your personal google drive\n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, the path to your Drive should be \"/content/drive/My Drive\". You may check this by clicking the file icon in\n",
    "the toolbar on the left side of Colab. From there you can navigate through your file tree and copy the path of any\n",
    "file in your Drive. \n",
    "\n",
    "Next, add the open-kbp directory to your path."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Add all files to path related to open-kbp. \n",
    "# A directory 'train-pats' with all training patient data should be included in open-kbp\n",
    "import sys\n",
    "primary_directory = '/content/drive/My Drive/open-kbp'\n",
    "sys.path.insert(0, primary_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOa3thQo8z_q"
   },
   "source": [
    "Import all necessary packages for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "vnvwlt8r80eR",
    "outputId": "a04e14a4-6671-4d85-eb0f-ed6c63312323",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x #  This ensures you use the newest version of tensorflow\n",
    "%tensorflow_version 2.x # Use tensorflow 2\n",
    "\n",
    "# Import provided classes and functions\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from provided_code.data_loader import DataLoader\n",
    "from provided_code.dose_evaluation_class import DoseEvaluator\n",
    "from provided_code.network_functions import PredictionModel\n",
    "from provided_code.utils import get_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSmow21srjCI"
   },
   "source": [
    "The functions loaded from _provided\\_code_ are written for this competition, and you can access them via the file \n",
    "explorer on the left hand side of the Colab window. You're welcome to change them as much as \n",
    "you'd like. Keep in mind, however, that on Colab any changes you make to the files in your Google Drive (e.g., files in\n",
    " _provided\\_code_ directory) will only be recognized by Colab when the _Runtime_ is restarted via the Restart \n",
    " Runtime option in the top toolbar. If you implement a neural network, we urge you to you start with the provided \n",
    " network architecture and network functions. The neural network we provide is only meant to be a template, and will not \n",
    " be a competitive model without some significant modifications.\n",
    "\n",
    "Before we run anything, first define the paths where the provided data is stored and where the results (e.g., models, predictions) should be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFJEIaar-d2r",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define project directories\n",
    "primary_directory = Path().resolve()  # directory where everything is stored\n",
    "provided_data_dir = primary_directory / \"provided-data\"\n",
    "training_data_dir = provided_data_dir / \"train-pats\"\n",
    "validation_data_dir = provided_data_dir / \"validation-pats\"\n",
    "testing_data_dir = provided_data_dir / \"test-pats\"\n",
    "results_dir = primary_directory / \"results\"  # where any data generated by this code (e.g., predictions, models) are stored"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Name the model. This name will be used to label directories containing the results that the model generates. Also, \n",
    "define how many epochs the model should be trained for. It will likely take a large number of epochs (e.g., 100-200)\n",
    "to get good results. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_time = False  # Only change this to True when the model has been fully tuned on the validation set\n",
    "prediction_name = \"baseline\"  # Name model to train and number of epochs to train it for\n",
    "num_epochs = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve the paths for all patient directories in the training set and seperate them into a list of paths for training \n",
    "a model and another for hold-out testing. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the data directory \n",
    "training_plan_paths = get_paths(training_data_dir)  # gets the path of each plan's directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize a data loader for the training set data, and use it to initialize a prediction model object. Call the\n",
    "train_model method to train the model for the predefined number of epochs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train a model\n",
    "data_loader_train = DataLoader(training_plan_paths)\n",
    "dose_prediction_model_train = PredictionModel(data_loader_train, results_dir, prediction_name,  \"train\")\n",
    "dose_prediction_model_train.train_model(epochs=num_epochs, save_frequency=1, keep_model_history=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that during training we will only keep models that are __save_frequency * keep_model_history__ epochs back from the\n",
    "current epoch. We do this because models are very large (~1 GB). \n",
    "\n",
    "Now that the model is trained we can use it to predict the dose for a set of hold-out patients from the validation or \n",
    "testing set. The code block below gets the paths of all plans in the hold out set you selected earlier.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define hold out set\n",
    "hold_out_data_dir = validation_data_dir if test_time is False else testing_data_dir\n",
    "stage_name, _ = hold_out_data_dir.stem.split(\"-\")\n",
    "hold_out_plan_paths = get_paths(hold_out_data_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by making a new data loader for the held-out set, and use it to predict (and save) a \n",
    "set of out-of-sample dose distributions. Note that we change the mode of the data loader to 'dose_prediction' to \n",
    "load only the data needed to make a prediction.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Predict dose for the held out set\n",
    "data_loader_hold_out = DataLoader(hold_out_plan_paths)\n",
    "dose_prediction_model_hold_out = PredictionModel(data_loader_hold_out, results_dir, model_name=prediction_name, stage=stage_name)\n",
    "dose_prediction_model_hold_out.predict_dose(epoch=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load each predicted dose distribution and evaluate it against the ground truth using the \n",
    "competition metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # Evaluate dose metrics\n",
    "data_loader_hold_out_eval = DataLoader(hold_out_plan_paths)\n",
    "prediction_paths = get_paths(dose_prediction_model_hold_out.prediction_dir, extension=\"csv\")\n",
    "hold_out_prediction_loader = DataLoader(prediction_paths)\n",
    "dose_evaluator = DoseEvaluator(data_loader_hold_out_eval, hold_out_prediction_loader)\n",
    "\n",
    "# print out scores if data was left for a hold out set\n",
    "if not data_loader_hold_out_eval.patient_paths:\n",
    "    print(\"No patient information was given to calculate metrics\")\n",
    "else:\n",
    "    dose_evaluator.evaluate()\n",
    "    dvh_score, dose_score = dose_evaluator.get_scores()\n",
    "    print(f\"For this out-of-sample test on {stage_name}:\\n\\tthe DVH score is {dvh_score:.3f}\\n\\tthe dose score is {dose_score:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you're happy with your dose distributions you can zip up the predictions with the code block below. The zipped file\n",
    "will contain the dose distributions for the validation set. It can be uploaded directly to CodaLab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Zip dose to submit\n",
    "submission_dir = results_dir / \"submissions\"\n",
    "submission_dir.mkdir(exist_ok=True)\n",
    "shutil.make_archive(str(submission_dir / prediction_name), \"zip\", dose_prediction_model_hold_out.prediction_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "open-kbp-introduction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-3642c69f",
   "language": "python",
   "display_name": "PyCharm (open-kbp-competition)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
